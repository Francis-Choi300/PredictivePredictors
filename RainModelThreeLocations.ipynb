{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354de36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "import urllib\n",
    "import urllib.parse as urlp\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_time_series(start_date,end_date,latitude,longitude,variable):\n",
    "    \"\"\"\n",
    "    Calls the data rods service to get a time series\n",
    "    \"\"\"\n",
    "    base_url = \"https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi\"\n",
    "    query_parameters = {\n",
    "        \"variable\": variable,\n",
    "        \"type\": \"asc2\",\n",
    "        \"location\": f\"GEOM:POINT({longitude}, {latitude})\",\n",
    "        \"startDate\": start_date,\n",
    "        \"endDate\": end_date,\n",
    "    }\n",
    "    full_url = base_url+\"?\"+ \\\n",
    "         \"&\".join([\"{}={}\".format(key,urlp.quote(query_parameters[key])) for key in query_parameters])\n",
    "    print(full_url)\n",
    "    iteration = 0\n",
    "    done = False\n",
    "    while not done and iteration < 5:\n",
    "        r=requests.get(full_url)\n",
    "        if r.status_code == 200:\n",
    "            done = True\n",
    "        else:\n",
    "            iteration +=1\n",
    "    \n",
    "    if not done:\n",
    "        raise Exception(f\"Error code {r.status_code} from url {full_url} : {r.text}\")\n",
    "    \n",
    "    return r.text\n",
    "\n",
    "def parse_time_series(ts_str):\n",
    "    \"\"\"\n",
    "    Parses the response from data rods.\n",
    "    \"\"\"\n",
    "    lines = ts_str.split(\"\\n\")\n",
    "    parameters = {}\n",
    "    for line in lines[2:11]:\n",
    "        key,value = line.split(\"=\")\n",
    "        parameters[key] = value\n",
    "    \n",
    "    \n",
    "    df = pd.read_table(io.StringIO(ts_str),sep=\"\\t\",\n",
    "                       names=[\"time\",\"data\"],\n",
    "                       header=10,parse_dates=[\"time\"])\n",
    "    return parameters, df\n",
    "\n",
    "#43.674901654747046, -79.53730583391066"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2335102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(lat,long):\n",
    "    df_ts = parse_time_series(\n",
    "            get_time_series(\n",
    "                start_date=\"2012-06-01T00\", \n",
    "                end_date=\"2022-05-31T23\",\n",
    "                latitude=lat,\n",
    "                longitude=long,\n",
    "                variable=\"GLDAS2:GLDAS_NOAH025_3H_v2.1:Rainf_f_tavg\"))\n",
    "    df_ts1 = parse_time_series(\n",
    "            get_time_series(\n",
    "                start_date=\"2000-01-01T00\", \n",
    "                end_date=\"2025-06-27T23\",\n",
    "                latitude=lat,\n",
    "                longitude=long,\n",
    "                variable=\"GLDAS2:GLDAS_NOAH025_3H_v2.1:Rainf_tavg\"))\n",
    "    df_ts2 = parse_time_series(\n",
    "            get_time_series(\n",
    "                start_date=\"2000-01-01T00\", \n",
    "                end_date=\"2025-06-27T23\",\n",
    "                latitude=lat,\n",
    "                longitude=long,\n",
    "                variable=\"GLDAS2:GLDAS_NOAH025_3H_v2.1:Qair_f_inst\"))\n",
    "    df_ts3 = parse_time_series(\n",
    "            get_time_series(\n",
    "                start_date=\"2000-01-01T00\", \n",
    "                end_date=\"2025-06-27T23\",\n",
    "                latitude=lat,\n",
    "                longitude=long,\n",
    "                variable=\"GLDAS2:GLDAS_NOAH025_3H_v2.1:Psurf_f_inst\"))\n",
    "    df1 = df_ts1[1].rename({'data': 'rain average'},axis='columns')\n",
    "    df2 = df_ts2[1].rename({'data': 'Humidity','time':'t2'},axis='columns')\n",
    "    df3 = df_ts3[1].rename({'data': 'Pressure (Pa)','time':'t3'},axis='columns')\n",
    "    combinedDF = pd.concat([df1,df2,df3], axis=1, join=\"inner\")\n",
    "    combinedDF.drop(columns=['t2', 't3'], inplace=True)\n",
    "    combinedDF['Year'] = pd.to_datetime(combinedDF['time']).dt.year\n",
    "    combinedDF['Month'] = pd.to_datetime(combinedDF['time']).dt.month\n",
    "    combinedDF['Day'] = pd.to_datetime(combinedDF['time']).dt.day\n",
    "    combinedDF['Hour'] = pd.to_datetime(combinedDF['time']).dt.hour\n",
    "    combinedDF.drop(columns=['time'], inplace=True)\n",
    "    combinedDF.isnull().sum()\n",
    "    combinedDF['Longitude'] = long\n",
    "    combinedDF['Latitude'] = lat\n",
    "    monthly_avg_humidity = combinedDF.groupby('Month')['Humidity'].mean()\n",
    "    monthly_avg_air_pressure = combinedDF.groupby('Month')['Pressure (Pa)'].mean()\n",
    "\n",
    "    X = combinedDF.drop('rain average', axis=1)  \n",
    "    y = combinedDF['rain average'].values\n",
    "\n",
    "\n",
    "\n",
    "    return combinedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d71c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_f_tavg&type=asc2&location=GEOM%3APOINT%28-79.54%2C%2043.67%29&startDate=2012-06-01T00&endDate=2022-05-31T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_tavg&type=asc2&location=GEOM%3APOINT%28-79.54%2C%2043.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3AQair_f_inst&type=asc2&location=GEOM%3APOINT%28-79.54%2C%2043.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3APsurf_f_inst&type=asc2&location=GEOM%3APOINT%28-79.54%2C%2043.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_f_tavg&type=asc2&location=GEOM%3APOINT%28-77.54%2C%2045.67%29&startDate=2012-06-01T00&endDate=2022-05-31T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_tavg&type=asc2&location=GEOM%3APOINT%28-77.54%2C%2045.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3AQair_f_inst&type=asc2&location=GEOM%3APOINT%28-77.54%2C%2045.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3APsurf_f_inst&type=asc2&location=GEOM%3APOINT%28-77.54%2C%2045.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_f_tavg&type=asc2&location=GEOM%3APOINT%28-81.54%2C%2041.67%29&startDate=2012-06-01T00&endDate=2022-05-31T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3ARainf_tavg&type=asc2&location=GEOM%3APOINT%28-81.54%2C%2041.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3AQair_f_inst&type=asc2&location=GEOM%3APOINT%28-81.54%2C%2041.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n",
      "https://hydro1.gesdisc.eosdis.nasa.gov/daac-bin/access/timeseries.cgi?variable=GLDAS2%3AGLDAS_NOAH025_3H_v2.1%3APsurf_f_inst&type=asc2&location=GEOM%3APOINT%28-81.54%2C%2041.67%29&startDate=2000-01-01T00&endDate=2025-06-27T23\n"
     ]
    }
   ],
   "source": [
    "combineDF = createData(43.67, -79.54)\n",
    "combineDF2 = createData(43.67+2,-79.54+2)\n",
    "combineDF3 = createData(43.67-2,-79.54-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cec0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 223437 entries, 0 to 223436\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   rain average   223437 non-null  float64\n",
      " 1   Humidity       223437 non-null  float64\n",
      " 2   Pressure (Pa)  223437 non-null  float64\n",
      " 3   Year           223437 non-null  int32  \n",
      " 4   Month          223437 non-null  int32  \n",
      " 5   Day            223437 non-null  int32  \n",
      " 6   Hour           223437 non-null  int32  \n",
      " 7   Longitude      223437 non-null  float64\n",
      " 8   Latitude       223437 non-null  float64\n",
      "dtypes: float64(5), int32(4)\n",
      "memory usage: 11.9 MB\n"
     ]
    }
   ],
   "source": [
    "masterDF = pd.concat([combineDF,combineDF2,combineDF3], ignore_index=True)\n",
    "masterDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a36d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def createModel(masterDF):\n",
    "    monthly_avg_humidity = masterDF.groupby('Month')['Humidity'].mean()\n",
    "    monthly_avg_air_pressure = masterDF.groupby('Month')['Pressure (Pa)'].mean()\n",
    "\n",
    "    X = masterDF.drop('rain average', axis=1)  \n",
    "    y = masterDF['rain average'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.3 , random_state = 89)\n",
    "    \n",
    "    linear_model = LinearRegression() \n",
    "    linear_model.fit(X_train, y_train)\n",
    "\n",
    "    predictions = linear_model.predict(X_test)\n",
    "    linear_model.score(X_test, predictions)\n",
    "    print(linear_model.score(X_test, y_test)) #test it\n",
    "    print(linear_model.coef_) #print significance of feature of linear model\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f48294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample prediction for our matrix\n",
    "def samplePrediction(linear_model):\n",
    "    sample = {'Humidity': [monthly_avg_humidity[6]],\n",
    "            'Pressure (Pa)': [monthly_avg_air_pressure[6]],\n",
    "            'Year': [2023],\n",
    "            'Month': [6],\n",
    "            'Day': [15],\n",
    "            'Hour': [12],\n",
    "            'Longitude': [-79.59],\n",
    "            'Latitude': [43.80],\n",
    "    }\n",
    "    sample_df = pd.DataFrame(sample)\n",
    "    linear_model.predict(sample_df)\n",
    "\n",
    "def displayData(combinedDF):\n",
    "    # display number of precipitation events above a certain threshold\n",
    "    threshold = 3.96e-05  # define threshold for heavy precipitation\n",
    "    heavy_precip_events = combinedDF[combinedDF['rain average'] > threshold]\n",
    "    print(f\"Number of heavy precipitation events: {len(heavy_precip_events)}\")\n",
    "    print(\"number of total events:\", len(combinedDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5808145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def createPickle(linear_model):\n",
    "    with open('rain_model_three_locations.pkl','wb') as f:\n",
    "        pickle.dump(linear_model, f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "135b78ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8344900666450409\n",
      "[ 8.01080040e+04  1.45818458e+00  2.34065747e+01 -3.34836130e+01\n",
      " -7.20965885e-02  2.58072070e-01  1.49203260e+03  1.49203260e+03]\n"
     ]
    }
   ],
   "source": [
    "linear_model = createModel(masterDF)\n",
    "createPickle(linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf6d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
